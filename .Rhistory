wine_arima
#forecast arima model with 10 points
wine_arima_forecast <- forecast(wine_arima, h=10)
plot(wine_arima_forecast)
plot(wine_arima_forecast, ylab="Bottles of Wine", xlab="Time")
plot(wine_arima_forecast, main="Wine ARIMA Forecast", ylab="Bottles of Wine", xlab="Time")
#Holts Winter model
wine_hw <- HoltWinters(wineind, beta=FALSE, gamma=TRUE)
wine_hw
#HW forecase
wine_hw_forecast <- forecast(wine_hw, h=10)
plot(wine_hw_forecast)
plot(wine_hw_forecast, ylab="Bottles of Wine", xlab="Time", main="Wine Holt Winters Forecast")
install.packages(ggplot2)
library(tidyverse)
AirPassengers
ggplot(data=AirPassengers)
ggplot(data=AirPassengers, aes(x=time, y=value))
AirPassengers
#load data
library(datasets)
library(forecast)
#get to know data
help("AirPassengers")
AirPassengers
#plot data
plot.ts(AirPassengers, ylab="Totals of International Airline Passengers", main="Monthly Airline Passenger Numbers 1949-1960")
#transform data since seasonality is present
log_AirPassengers <- log(AirPassengers)
plot.ts(log_AirPassengers, ylab="Logged Totals of International Airline Passengers", main="Monthly Airline Passenger Numbers 1949-1960")
#decomp
decomp_AirPassengers <- decompose(AirPassengers)
head(decomp_AirPassengers)
plot(decomp_AirPassengers)
#decomp
decomp_AirPassengers <- decompose(AirPassengers)
head(decomp_AirPassengers)
plot(decomp_AirPassengers, main="Decomposition of Air Passengers")
plot(decomp_AirPassengers)
head(decomp_AirPassengers)
#HoltWinters forecast with seasonality
hwws_AirPassengers <- HoltWinters(log_AirPassengers, beta=FALSE)
hwws_AirPassengers
#HoltWinters forecast with seasonality
hwws_AirPassengers <- HoltWinters(log_AirPassengers)
hwws_AirPassengers
#HoltWinters forecast with seasonality
hwws_AirPassengers <- HoltWinters(log_AirPassengers, beta=FALSE)
hwws_AirPassengers
#forecast next 10 data points
forecasthwws <- forecast(hwws_AirPassengers, h=10)
plot(forecasthwws, main="Holt Winters Forecast with Seasonality", ylab="Logged Scale; 1,000 Passengers", xlab="Time")
#HoltWinters forecast without seasonality
hwwos_AirPassengers <- HoltWinters(log_AirPassengers, beta=FALSE, gamma=FALSE)
hwwos_AirPassengers
#forecast next 10 data points
forecasthwwos <- forecast(hwwos_AirPassengers, h=10)
plot(forecasthwwos, main="Holt Winters Forecast without Seasonality", ylab="Logged Scale; 1,000 Passengers", xlab="Time")
#load data
library("forecast")
#get a feel for data
summary(wineind)
head(wineind)
plot.ts(wineind, main="Austrailian Wine Sales by Wine Makers in Bottles; Monthly 1980-1994", ylab="Total Sales")
head(wineind)
plot.ts(wineind, main="Austrailian Wine Sales by Wine Makers in Bottles; Monthly 1980-1994", ylab="Total Sales")
#differences 1
wine_d1 = diff(wineind, differences=1)
plot.ts(wine_d1, main="Wine - Differences = 1", ylab="Sales", ylim=c(-30000, 30000))
#differences 2
wine_d2 = diff(wineind, differences=2)
plot.ts(wine_d2, main="Wine - Differences = 2", ylab="Sales", ylim=c(-30000, 30000))
#diff 1 better model
#auto correlation
acf(wine_d1, lag.max=20)
#partial auto correlation
pacf(wine_d2)
#auto arima
auto.arima(wineind)
#arima model
wine_arima <- arima(wineind, order=c(1,1,2), seasonal=list(order=c(0,1,1), period=12))
#forecast arima model with 10 points
wine_arima_forecast <- forecast(wine_arima, h=10)
plot(wine_arima_forecast, main="Wine ARIMA Forecast", ylab="Bottles of Wine", xlab="Time")
#Holts Winter model no trend, yes seasonality
wine_hw <- HoltWinters(wineind, beta=FALSE, gamma=TRUE)
wine_hw
#HW forecast with 10 points
wine_hw_forecast <- forecast(wine_hw, h=10)
plot(wine_hw_forecast, ylab="Bottles of Wine", xlab="Time", main="Wine Holt Winters Forecast")
#load data
library(ISLR)
library(splines)
#get a feel for data
head(Wage)
summary(Wage)
#wage below $250k
wagesubset <- subset(Wage,wage<250)
#remove region and log wage from subset
wagesubset = subset(wagesubset, select = -c(logwage,region))
#put education variable in numeric
wagesubset$edu <- as.numeric(wagesubset$education)
summary(wagesubset)
#build simple model
simpmod <- lm(wage~.-education, data=wagesubset)
#effects plot
plot(allEffects(simpmod))
#build simple model
simpmod <- lm(wage~.-education, data=wagesubset)
#effects plot
plot(allEffects(simpmod))
library(effects)
#build simple model
simpmod <- lm(wage~.-education, data=wagesubset)
#effects plot
plot(allEffects(simpmod))
#load data
library(ISLR)
library(effects)
library(splines)
#get a feel for data
head(Wage)
summary(Wage)
#wage below $250k
wagesubset <- subset(Wage,wage<250)
#remove region and log wage from subset
wagesubset = subset(wagesubset, select = -c(logwage,region))
#put education variable in numeric
wagesubset$edu <- as.numeric(wagesubset$education)
summary(wagesubset)
#build simple model
simpmod <- lm(wage~.-education, data=wagesubset)
#effects plot
plot(allEffects(simpmod))
View(wagesubset)
#first try of model with poly and bs
firsttrymod <- lm(wage~poly(edu,2)+bs(age)+.-education, data=wagesubset)
#find best model
step(firsttrymod)
#best model
bestmod <- lm(wage ~ poly(edu, 2) + bs(age) + year + maritl + race + jobclass + health + health_ins, data = wagesubset)
#effect plot
plot(allEffects(bestmod))
#above median subset
wagesubset$aboveMedian <- wagesubset$wage >= median(wagesubset$wage)
#binomial model
abovemedianmod <- glm(aboveMedian~poly(edu, 2) + bs(age) + year + maritl + race + jobclass + health + health_ins, data = wagesubset, family="binomial")
#predict
preds <- predict(abovemedianmod, type = "response")
# Create a contingency table by comparing the predicted values (using the probability cut off of 0.5)
tabs <- table(wagesubset$aboveMedian, preds >= 0.5)
# Print the contingency table
tabs
# Calculate the proportion of misclassifications made by the model
(sum(tabs) - sum(diag(tabs))) / dim(wagesubset)[1]
#correctness
1-((sum(tabs) - sum(diag(tabs))) / dim(wagesubset)[1])
# Calculate the proportion of misclassifications made by the model
1- ((sum(tabs) - sum(diag(tabs))) / dim(wagesubset)[1])
library(forecastML)
library(lubridate)
library(prophet)
data_seatbelts$ds <- seq(as.Date("1969-01-01"),as.Date("1984-12-01"), by = "months")
data_seatbelts$y <- data_seatbelts$DriversKilled
data_seatbelts$law <- as.factor(data_seatbelts$law)
seatbeltsafteytrain <- data_seatbelts[,-c(1)]
prophetmod <- prophet(seatbelsafteytrain, fit=FALSE)
prophetmod <- add_regressor(prophetmod, "kms")
prophetmod <- add_regressor(prophetmod, "PetrolPrice")
prophetmod <- add_regressor(prophetmod, "law")
prophetmod <- fit.prophet(prophetmod, seatbeltsafteytrain)
seatbeltsafetytest <- seatbeltsafteytrain[,-5]
forecast1 <- predict(prophetmod,seatbeltsafetytest)
plot(prophetmod, forecast1)
#load libraries
library(forecastML)
library(lubridate)
library(prophet)
#fix date format and name it ds
data_seatbelts$ds <- seq(as.Date("1969-01-01"),as.Date("1984-12-01"), by = "months")
#create new y column
data_seatbelts$y <- data_seatbelts$DriversKilled
#fix to be a factor
data_seatbelts$law <- as.factor(data_seatbelts$law)
#create training set and do not fit it
seatbeltsafteytrain <- data_seatbelts[,-c(1)]
prophetmod <- prophet(seatbelsafteytrain, fit=FALSE)
#add co-regressors
prophetmod <- add_regressor(prophetmod, "kms")
prophetmod <- add_regressor(prophetmod, "PetrolPrice")
prophetmod <- add_regressor(prophetmod, "law")
#fit model to training set
prophetmod <- fit.prophet(prophetmod, seatbeltsafteytrain)
#create test set
seatbeltsafetytest <- seatbeltsafteytrain[,-5]
#create forecast
forecast1 <- predict(prophetmod,seatbeltsafetytest)
plot(prophetmod, forecast1)
#plot
plot(prophetmod, forecast1)
prophet_plot_components(prophetmod, forecast1)
download.file("https://opendata.arcgis.com/api/v3/datasets/97603afcff00443f874acbe03c9e794a_0/downloads/data?format=csv&spatialRefId=3857&where=1%3D1", "./Raw Data/PlacesofWorship.csv")
download.file("https://opendata.arcgis.com/api/v3/datasets/97603afcff00443f874acbe03c9e794a_0/downloads/data?format=csv&spatialRefId=3857&where=1%3D1", "./RawData/PlacesofWorship.csv")
download.file("https://www.imls.gov/sites/default/files/2022-07/pls_fy2020_csv.zip", "./PublicLibrariesSurvey.zip")
#unzip file
unzip("PublicLibrariesCurvey.zip",exdir="RawData")
#unzip file
unzip("PublicLibrariesSurvey.zip",exdir="RawData")
source('~/.active-rstudio-document', echo=TRUE)
#polling locations
pollinglocations <- read.csv("https://raw.githubusercontent.com/PublicI/us-polling-places/update-2020/data/west_virginia/output/West%20Virginia_2020-11-03.csv", sep=",")
write.csv(pollinglocations, "RawData/pollingLocations.csv")
knitr::opts_chunk$set(echo = TRUE)
library(car)
data("Mroz")
head(Mroz)
plot(Mroz)
#create simple model
simpMod <- lm(lfp~., data=Mroz)
plot(allEffects(simpMod))
#effects library
library(effects)
plot(allEffects(simpMod))
library(splines)
head(Mroz)
summary((Mroz))
#create simple model
simpMod <- lm(lfp~., data=Mroz, family="binomial")
plot(allEffects(simpMod))
summary((Mroz))
#create simple model
simpMod <- lm(lfp~., data=Mroz, family="binomial")
summary((Mroz))
typeof((Mroz$k5))
typeof((Mroz$k618))
typeof((Mroz$age))
typeof((Mroz$wc))
typeof((Mroz$wc))
typeof((Mroz$hc))
typeof((Mroz$hc))
typeof((Mroz$lwg))
View(Mroz)
typeof((Mroz$inc))
#create simple model
simpMod <- lm(lfp~., data=Mroz, family="binomial")
library(mlogit)
install.packages("mlogit", lib="/Library/Frameworks/R.framework/Versions/4.0/Resources/library")
library(mlogit)
data("Fishing")
head(Fishing)
plot(Fishing)
#create simple model
simpMod <- lm(lfp~., data=Mroz, family="binomial")
#create simple model
simpMod <- lm(lfp~., data=Mroz)
plot(allEffects(simpMod))
#create simple model
simpMod <- lm(lfp~., data=Mroz)
View(simpMod)
#create simple model
simpMod <- glm(lfp~., data=Mroz, family="binomial")
plot(allEffects(simpMod))
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+., data=Mrox, family="binomial")
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k5)+bs(k618)+bs(age)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k5)+bs(k618)+bs(age)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~+bs(k618)+bs(age)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~+bs(age)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
+bs(k618)
#model with spline
firstTry <- glm(lfp~+bs(k618)+bs(age)+., data=Mroz, family="binomial")
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k5)+bs(k618)+bs(age)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+poly(lwg,2)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+poly(lwg,2)+poly(k5,5)+., data=Mroz, family="binomial")
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+poly(lwg,2)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+poly(lwg,2)+poly(inc,2)., data=Mroz, family="binomial")
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+poly(lwg,2)+poly(inc,2)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+poly(lwg,2)+poly(inc,3)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+poly(lwg,2)+poly(inc,4)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+poly(lwg,2)+poly(inc,5)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#model with spline
firstTry <- glm(lfp~bs(k618)+bs(age)+poly(lwg,2)+., data=Mroz, family="binomial")
plot(allEffects(firstTry))
#find better model
step(firstTry)
#better model using step
betterModel <- glm(lfp~bs(age)+poly(lwg, 2)+k5+inc, data = Mroz, family="binomial")
plot(allEffects((betterModel)))
library(mlogit)
data("Fishing")
head(Fishing)
table(Fishing$mode, Fishing$price.beach)
library(nnet)
#model
mod1 <- multinom(mode~., data=Fishing)
summary(mod1)
#step
step(mod1)
modelingBetter <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing)
#cross validation to see how accurate
set.seed(321)
test <- sample(1:1182,300,replace=FALSE)
ModT <- multinom(mode~., data=Fishing[-test])
preds <- predict(ModT,newdata=Fishing[test,])
head(preds)
sum(table(preds,Fishing$mode[test]))-sum(diag(table(preds,Fishing$mode[test])))
#cross validation for accuracy
ModT2 <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing[-test])
library(nnet)
library(mlogit)
data("Fishing")
head(Fishing)
#model 1
mod1 <- multinom(mode~., data=Fishing)
summary(mod1)
#cross validation to see how accurate
set.seed(321)
test <- sample(1:1182,300,replace=FALSE)
ModT <- multinom(mode~., data=Fishing[-test])
#how accurate
preds <- predict(ModT,newdata=Fishing[test,])
head(preds)
sum(table(preds,Fishing$mode[test]))-sum(diag(table(preds,Fishing$mode[test])))
#156 out of 300 are wrong
#step
step(mod1)
#better model but has no income component
modelingBetter <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing)
#cross validation for accuracy
ModT2 <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing[-test])
#better model but has no income component
modelingBetter <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing)
#cross validation for accuracy
ModT2 <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing[-test])
#better model but has no income component
modelingBetter <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing)
#cross validation for accuracy
ModT2 <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing)
#cross validation for accuracy
ModT2 <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing[-test])
test <- sample(1:1182,300,replace=FALSE)
#cross validation for accuracy
ModT2 <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing[-test])
#better model but has no income component
modelingBetter <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing)
#cross validation for accuracy
ModT2 <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing[-test])
#cross validation to see how accurate
set.seed(123)
test <- sample(1:1182,300,replace=FALSE)
#cross validation for accuracy
ModT2 <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing[-test])
library(nnet)
library(mlogit)
data("Fishing")
head(Fishing)
#model 1
mod1 <- multinom(mode~., data=Fishing)
summary(mod1)
#cross validation to see how accurate
set.seed(123)
test <- sample(1:1182,300,replace=FALSE)
ModT <- multinom(mode~., data=Fishing[-test])
#how accurate
preds <- predict(ModT,newdata=Fishing[test,])
head(preds)
sum(table(preds,Fishing$mode[test]))-sum(diag(table(preds,Fishing$mode[test])))
#156 out of 300 are wrong
#step
step(mod1)
#better model but has no income component
modelingBetter <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing)
#cross validation for accuracy
ModT2 <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing[-test])
#how accurate
preds2 <- predict(ModT2,newdata=Fishing[test,])
head(preds2)
sum(table(preds2,Fishing$mode[test]))-sum(diag(table(preds2,Fishing$mode[test])))
#156 out of 300 are wrong
sum(table(preds2,Fishing$mode[test]))-sum(diag(table(preds2,Fishing$mode[test])))
plot(allEffects(simpMod))
plot(allEffects(firstTry))
#find better model
step(firstTry)
#better model using step
betterModel <- glm(lfp~bs(age)+poly(lwg, 2)+k5+inc, data = Mroz, family="binomial")
plot(allEffects((betterModel)))
# Print the contingency table
tabs
#above median subset
wagesubset$aboveMedian <- wagesubset$wage >= median(wagesubset$wage)
library(nnet)
library(mlogit)
data("Fishing")
head(Fishing)
#model 1
mod1 <- multinom(mode~., data=Fishing)
summary(mod1)
#cross validation to see how accurate
set.seed(123)
test <- sample(1:1182,300,replace=FALSE)
ModT <- multinom(mode~., data=Fishing[-test])
#how accurate
preds <- predict(ModT,newdata=Fishing[test,])
head(preds)
sum(table(preds,Fishing$mode[test]))-sum(diag(table(preds,Fishing$mode[test])))
#156 out of 300 are wrong
#step
step(mod1)
#better model but has no income component
modelingBetter <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing)
#cross validation for accuracy
ModT2 <- multinom(mode~price.beach+price.pier+price.boat+price.charter+catch.beach+catch.pier+catch.boat, data=Fishing[-test])
#how accurate
preds2 <- predict(ModT2,newdata=Fishing[test,])
head(preds2)
sum(table(preds2,Fishing$mode[test]))-sum(diag(table(preds2,Fishing$mode[test])))
#148 out of 300 are wrong
#confusion matrix
preds3 <- predict(betterModel, type = "response")
# Create a contingency table by comparing the predicted values (using the probability cut off of 0.5)
tabs <- table(Mroz$lfp, preds >= 0.5)
#confusion matrix
preds3 <- predict(betterModel, type = "response")
# Create a contingency table by comparing the predicted values (using the probability cut off of 0.5)
tabs3 <- table(Mroz$lfp, preds >= 0.5)
# Create a contingency table by comparing the predicted values (using the probability cut off of 0.5)
tabs3 <- table(Mroz$lfp, preds3 >= 0.5)
# Print the contingency table
tabs3
# correctness
1- ((sum(tabs3) - sum(diag(tabs3))) / dim(Mroz)[1])
#load packages
library(tidyverse) # I literally don't know how anyone uses R without this.
library(usdata) # has a nice function for converting state abbreviations to state names and vis versa
#read in data
fileList <- list.files(path="./RawData", pattern="*.csv")
fileContent <- lapply(fileList, read_csv)
fileContent <- lapply(fileList, read_csv)
getwd()
library(utils)
#download Places of Worship File
download.file("https://opendata.arcgis.com/api/v3/datasets/97603afcff00443f874acbe03c9e794a_0/downloads/data?format=csv&spatialRefId=3857&where=1%3D1", "./RawData/PlacesofWorship.csv")
#load packages
library(tidyverse) # I literally don't know how anyone uses R without this.
library(usdata) # has a nice function for converting state abbreviations to state names and vis versa
#read in data
fileList <- list.files(path="./RawData", pattern="*.csv")
fileContent <- lapply(fileList, read_csv)
getwd()
setwd("/Users/lauren/Desktop/Data Driven WV/BEAD2")
fileContent <- lapply(fileList, read_csv)
#load packages
library(tidyverse) # I literally don't know how anyone uses R without this.
library(usdata) # has a nice function for converting state abbreviations to state names and vis versa
#read in data
fileList <- list.files(path="./RawData", pattern="*.csv")
fileContent <- lapply(fileList, read_csv)
library(utils)
#download Places of Worship File
download.file("https://opendata.arcgis.com/api/v3/datasets/97603afcff00443f874acbe03c9e794a_0/downloads/data?format=csv&spatialRefId=3857&where=1%3D1", "./RawData/PlacesofWorship.csv")
library(utils)
#timeout error fix
options(timeout = max(300, getOption("timeout")))
#download Places of Worship File
download.file("https://opendata.arcgis.com/api/v3/datasets/97603afcff00443f874acbe03c9e794a_0/downloads/data?format=csv&spatialRefId=3857&where=1%3D1", "./RawData/PlacesofWorship.csv")
#Download zip file from Public Libraries Survey
download.file("https://www.imls.gov/sites/default/files/2022-07/pls_fy2020_csv.zip", "./PublicLibrariesSurvey.zip")
#unzip file
unzip("PublicLibrariesSurvey.zip",exdir="RawData")
#polling locations
pollinglocations <- read.csv("https://raw.githubusercontent.com/PublicI/us-polling-places/update-2020/data/west_virginia/output/West%20Virginia_2020-11-03.csv", sep=",")
write.csv(pollinglocations, "RawData/pollingLocations.csv")
#load packages
library(tidyverse) # I literally don't know how anyone uses R without this.
library(usdata) # has a nice function for converting state abbreviations to state names and vis versa
#read in data
fileList <- list.files(path="./RawData", pattern="*.csv")
fileContent <- lapply(fileList, read_csv)
